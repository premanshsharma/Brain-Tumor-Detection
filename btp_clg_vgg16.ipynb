{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "btp-clg vgg16.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/premanshsharma/Brain-Tumor-Detection/blob/main/btp_clg_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, BatchNormalization, Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "import keras,os\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "BCAPzQmXCTMY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57FoYU-82dug",
        "outputId": "987b6e93-c181-46c3-8c10-dbcf2021ab3b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder()\n",
        "encoder.fit([[0], [1]]) \n",
        "\n",
        "# 0 - Tumor\n",
        "# 1 - Normal\n",
        "# This cell updates result list for images with tumor\n",
        "\n",
        "data = []\n",
        "paths = []\n",
        "result = []\n",
        "\n",
        "for r, d, f in os.walk(r'/content/gdrive/MyDrive/Brain Tumor Detection/BRAIN_MRI_IMAGE_DATA_SET/data sets/yes'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224,224))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (224,224,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[0]]).toarray())\n",
        "paths = []\n",
        "\n",
        "for r, d, f in os.walk(r'/content/gdrive/MyDrive/Brain Tumor Detection/BRAIN_MRI_IMAGE_DATA_SET/data sets/no'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224,224))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (224,224,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[1]]).toarray())"
      ],
      "metadata": {
        "trusted": true,
        "id": "SPDkC9aBCTMa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "data.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "q9f_PfzkCTMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ffa8cc-0a86-4419-893a-82ea4ba61fef"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2891, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.array(result)\n",
        "result = result.reshape(2891,2)"
      ],
      "metadata": {
        "id": "abUknXZxHpLv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data, result, test_size=0.2, shuffle = True, random_state = 8)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state= 8)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nxeCda-QCTMb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=2, activation=\"softmax\"))\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "opt = Adam(lr=0.001)\n",
        "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "3MY1eQzrCTMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "2jr6WYMlCTMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deda7fd2-4786-4a3e-dc6b-99b7a0508270"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1734, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs = 50, batch_size = 40, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "trusted": true,
        "id": "MJuwLt2pCTMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d56467-0f0d-4c03-811c-28209433a12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "44/44 [==============================] - 3572s 81s/step - loss: 285.5519 - accuracy: 0.5542 - val_loss: 0.5605 - val_accuracy: 0.7249\n",
            "Epoch 2/50\n",
            "44/44 [==============================] - 3627s 83s/step - loss: 0.5848 - accuracy: 0.6972 - val_loss: 0.5435 - val_accuracy: 0.7370\n",
            "Epoch 3/50\n",
            "44/44 [==============================] - 3566s 81s/step - loss: 0.5487 - accuracy: 0.7324 - val_loss: 0.5488 - val_accuracy: 0.7318\n",
            "Epoch 4/50\n",
            "44/44 [==============================] - 3546s 81s/step - loss: 0.5405 - accuracy: 0.7255 - val_loss: 0.5515 - val_accuracy: 0.7388\n",
            "Epoch 5/50\n",
            "22/44 [==============>...............] - ETA: 27:56 - loss: 0.5393 - accuracy: 0.7273"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(\n",
        "    x_test,\n",
        "    batch_size=None,\n",
        "    verbose=\"auto\",\n",
        "    steps=None,\n",
        "    callbacks=None,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    use_multiprocessing=False,\n",
        ")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Z6EbjGHYCTMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Test', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "GikixC26CTMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train = history.history['accuracy']\n",
        "loss_val = history.history['val_accuracy']\n",
        "epochs = range(1,6)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "vjY8T0wgCTMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('loss', 'accuracy')\n",
        "model.evaluate(\n",
        "    x=x_test,\n",
        "    y=y_test,\n",
        "    batch_size=40,\n",
        "    verbose=\"auto\",\n",
        "    sample_weight=None,\n",
        "    steps=None,\n",
        "    callbacks=None,\n",
        "    max_queue_size=10,\n",
        "    workers=1,\n",
        "    use_multiprocessing=False,\n",
        "    return_dict=False,\n",
        ")\n",
        "print(model.metrics_names)\n",
        "print(model)"
      ],
      "metadata": {
        "trusted": true,
        "id": "TnxCCokvCTMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.confusion_matrix(\n",
        "    y_test,\n",
        "    pred,\n",
        "    num_classes=None,\n",
        "    weights=None,\n",
        "    dtype=tf.dtypes.int32,\n",
        "    name=None\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "pA8kdso6CTMg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}