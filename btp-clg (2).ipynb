{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport keras \nfrom keras.models import Sequential\nfrom keras.layers import Dropout, BatchNormalization, Dense, Conv2D, MaxPool2D , Flatten\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('dark_background')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder \nimport keras,os\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-18T11:40:50.431557Z","iopub.execute_input":"2022-06-18T11:40:50.432676Z","iopub.status.idle":"2022-06-18T11:40:57.503817Z","shell.execute_reply.started":"2022-06-18T11:40:50.432620Z","shell.execute_reply":"2022-06-18T11:40:57.502562Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"encoder = OneHotEncoder()\nencoder.fit([[0], [1]]) \n\n# 0 - Tumor\n# 1 - Normal\n# This cell updates result list for images with tumor\n\ndata = []\npaths = []\nresult = []\n\nfor r, d, f in os.walk(r'../input/brain-tumor-detection/yes'):\n    for file in f:\n        if '.jpg' in file:\n            paths.append(os.path.join(r, file))\n\nfor path in paths:\n    img = Image.open(path)\n    img = img.resize((224,224))\n    img = np.array(img)\n    if(img.shape == (224,224,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[0]]).toarray())\npaths = []\n\nfor r, d, f in os.walk(r'../input/brain-tumor-detection/no'):\n    for file in f:\n        if '.jpg' in file:\n            paths.append(os.path.join(r, file))\n\nfor path in paths:\n    img = Image.open(path)\n    img = img.resize((224,224))\n    img = np.array(img)\n    if(img.shape == (224,224,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[1]]).toarray())","metadata":{"execution":{"iopub.status.busy":"2022-06-18T11:40:57.505935Z","iopub.execute_input":"2022-06-18T11:40:57.506894Z","iopub.status.idle":"2022-06-18T11:41:35.377170Z","shell.execute_reply.started":"2022-06-18T11:40:57.506857Z","shell.execute_reply":"2022-06-18T11:41:35.375898Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = np.array(data)\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-18T11:41:35.378924Z","iopub.execute_input":"2022-06-18T11:41:35.379491Z","iopub.status.idle":"2022-06-18T11:41:35.673532Z","shell.execute_reply.started":"2022-06-18T11:41:35.379440Z","shell.execute_reply":"2022-06-18T11:41:35.672304Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"result = np.array(result)\nresult = result.reshape(2891,2)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T11:41:35.675699Z","iopub.execute_input":"2022-06-18T11:41:35.676070Z","iopub.status.idle":"2022-06-18T11:41:35.685762Z","shell.execute_reply.started":"2022-06-18T11:41:35.676022Z","shell.execute_reply":"2022-06-18T11:41:35.684421Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(data, result, test_size=0.2, shuffle = True, random_state = 8)\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state= 8)\n# x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:45:21.241360Z","iopub.execute_input":"2022-06-18T13:45:21.242475Z","iopub.status.idle":"2022-06-18T13:45:21.898924Z","shell.execute_reply.started":"2022-06-18T13:45:21.242429Z","shell.execute_reply":"2022-06-18T13:45:21.898020Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=4096,activation=\"relu\"))\nmodel.add(Dense(units=2, activation=\"softmax\"))\nfrom tensorflow.keras.optimizers import Adam \nopt = Adam(lr=0.001)\nmodel.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:45:27.864816Z","iopub.execute_input":"2022-06-18T13:45:27.865294Z","iopub.status.idle":"2022-06-18T13:45:28.641408Z","shell.execute_reply.started":"2022-06-18T13:45:27.865258Z","shell.execute_reply":"2022-06-18T13:45:28.640242Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"y_train.shape\n# y_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:45:50.160259Z","iopub.execute_input":"2022-06-18T13:45:50.160734Z","iopub.status.idle":"2022-06-18T13:45:50.168673Z","shell.execute_reply.started":"2022-06-18T13:45:50.160698Z","shell.execute_reply":"2022-06-18T13:45:50.167616Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train, y_train, epochs = 10, batch_size = 40, validation_data = (x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T13:46:45.331771Z","iopub.execute_input":"2022-06-18T13:46:45.332308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(\n    x_test,\n    batch_size=None,\n    verbose=\"auto\",\n    steps=None,\n    callbacks=None,\n    max_queue_size=10,\n    workers=1,\n    use_multiprocessing=False,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Test', 'Validation'], loc='upper right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_train = history.history['accuracy']\nloss_val = history.history['val_accuracy']\nepochs = range(1,6)\nplt.plot(epochs, loss_train, 'g', label='Training accuracy')\nplt.plot(epochs, loss_val, 'b', label='validation accuracy')\nplt.title('Training and Validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('loss', 'accuracy')\nmodel.evaluate(\n    x=x_test,\n    y=y_test,\n    batch_size=40,\n    verbose=\"auto\",\n    sample_weight=None,\n    steps=None,\n    callbacks=None,\n    max_queue_size=10,\n    workers=1,\n    use_multiprocessing=False,\n    return_dict=False,\n)\nprint(model.metrics_names)\nprint(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.math.confusion_matrix(\n    y_test,\n    pred,\n    num_classes=None,\n    weights=None,\n    dtype=tf.dtypes.int32,\n    name=None\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}