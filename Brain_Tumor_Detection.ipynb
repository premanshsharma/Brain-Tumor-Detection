{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "btp-clg vgg16.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/premanshsharma/Brain-Tumor-Detection/blob/main/Brain_Tumor_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Brain Tumor Detection and Analysis of different algorithms."
      ],
      "metadata": {
        "id": "tXji3TRcgd6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, BatchNormalization, Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "import tensorflow as tf\n",
        "plt.style.use('dark_background')\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "BCAPzQmXCTMY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57FoYU-82dug",
        "outputId": "547e3ed8-2702-44e7-f2e5-9bf7647d306a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression And SVM Implementation"
      ],
      "metadata": {
        "id": "G30mme-ZKnpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Dataset For Training"
      ],
      "metadata": {
        "id": "odCtEXllgI_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalr = []\n",
        "pathslr = []\n",
        "resultlr = []\n",
        "for r, d, f in os.walk(r'/content/gdrive/MyDrive/Brain Tumor Detection/BRAIN_MRI_IMAGE_DATA_SET/data sets/yes'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            pathslr.append(os.path.join(r, file))\n",
        "for path in pathslr:\n",
        "    img = Image.open(path)\n",
        "    gray_image = ImageOps.grayscale(img)\n",
        "    img = img.resize((224,224))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (224,224, 3)):\n",
        "        nsamples, nx, ny = img.shape\n",
        "        img = img.reshape((nsamples,nx*ny))\n",
        "        datalr.append(np.array(img))\n",
        "        resultlr.append(0)\n",
        "pathslr = []\n",
        "print('yes', len(datalr), len(resultlr))\n",
        "for r, d, f in os.walk(r'/content/gdrive/MyDrive/Brain Tumor Detection/BRAIN_MRI_IMAGE_DATA_SET/data sets/no'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            pathslr.append(os.path.join(r, file))\n",
        "for path in pathslr:\n",
        "    img = Image.open(path)\n",
        "    gray_image = ImageOps.grayscale(img)\n",
        "    img = img.resize((224,224))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (224,224, 3)):\n",
        "        nsamples, nx, ny = img.shape\n",
        "        img = img.reshape((nsamples,nx*ny))\n",
        "        datalr.append(np.array(img))\n",
        "        resultlr.append(1)\n",
        "print('no', len(datalr), len(resultlr))"
      ],
      "metadata": {
        "id": "L60p6pdDKt94",
        "outputId": "49e6a7bb-02b1-4adf-e30a-620980ad4a61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes 1424 1424\n",
            "no 2891 2891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datalr = np.array(datalr)\n",
        "nsamples, nx, ny = datalr.shape\n",
        "# print(x)\n",
        "# \n",
        "datalr = datalr.reshape((nsamples,nx*ny))"
      ],
      "metadata": {
        "id": "g6LhG83bscMx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(datalr), len(resultlr))"
      ],
      "metadata": {
        "id": "fp2I3KQ_00ci",
        "outputId": "f140fe1e-4763-4ea2-98e4-7a344a7b458e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2891 2891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_trainlr, x_testlr, y_trainlr, y_testlr = train_test_split(datalr, resultlr, test_size=0.25, random_state=0)\n",
        "print(len(x_trainlr), len(x_testlr))"
      ],
      "metadata": {
        "id": "Rarc-ZHjYbbt",
        "outputId": "39716155-408d-4174-e02e-0e6ef2f19779",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2168 723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "s4s2BdSndwxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression is not taking all the data set into consideration."
      ],
      "metadata": {
        "id": "aqHxKwoXyo66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticRegr = LogisticRegression(solver='lbfgs', max_iter=100000)"
      ],
      "metadata": {
        "id": "QigZPL45YwKV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logisticRegr.fit(x_trainlr, y_trainlr)"
      ],
      "metadata": {
        "id": "5KGctOgBY2A3",
        "outputId": "af39bd45-6715-4369-8e24-c74478c51506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=100000)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = logisticRegr.predict(x_testlr)\n",
        "y_train_pred = logisticRegr.predict(x_trainlr)"
      ],
      "metadata": {
        "id": "40Mg5Z8G1aEa"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_testlr,y_test_pred)"
      ],
      "metadata": {
        "id": "ZyboPhq91ZCr",
        "outputId": "cb65a2bd-2b57-4fbc-c928-2670ba4dba86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.970954356846473"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_testlr,predictions)\n",
        "cm"
      ],
      "metadata": {
        "id": "Wzn8XxQnwCcD",
        "outputId": "21798e1f-6631-4d0b-eb59-e9dee9d01106",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[360,  15],\n",
              "       [  6, 342]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "sjU323qmd2Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "#    Linear Kernels\n",
        "# Polynomial Kernels\n",
        "# Radial Basis Function Kernel\n",
        "svr = SVC(kernel = 'linear',C = 1000)\n",
        "svr.fit(x_trainlr,y_trainlr)"
      ],
      "metadata": {
        "id": "MP6GAnXLhkUo",
        "outputId": "066f51f7-2002-4087-bba8-c7eddb483e73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1000, kernel='linear')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = svr.predict(x_testlr)\n",
        "y_train_pred = svr.predict(x_trainlr)"
      ],
      "metadata": {
        "id": "15pc12YLizD5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_testlr,y_test_pred)"
      ],
      "metadata": {
        "id": "7GxG0lY3jKIw",
        "outputId": "14687cb9-840c-46e2-9336-674df0617578",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9695712309820194"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_testlr,predictions)\n",
        "print(len(x_trainlr), len(x_testlr), len(y_test_pred))\n",
        "cm"
      ],
      "metadata": {
        "id": "tfPxP1Qskf1Y",
        "outputId": "78e9d696-e2a9-46e1-8031-7fac593c1d27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2168 723 723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[360,  15],\n",
              "       [  6, 342]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Implementation:- VGG16, VGG19"
      ],
      "metadata": {
        "id": "1-GmVhibKcM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder()\n",
        "encoder.fit([[0], [1]]) \n",
        "\n",
        "\n",
        "# 0 - Tumor\n",
        "# 1 - Normal\n",
        "# This cell updates result list for images with tumor\n",
        "\n",
        "data = []\n",
        "paths = []\n",
        "result = []\n",
        "data_for_svm = []\n",
        "for r, d, f in os.walk(r'/content/gdrive/MyDrive/Brain Tumor Detection/BRAIN_MRI_IMAGE_DATA_SET/data sets/yes'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224,224))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (224,224,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[0]]).toarray())\n",
        "paths = []\n",
        "for r, d, f in os.walk(r'/content/gdrive/MyDrive/Brain Tumor Detection/BRAIN_MRI_IMAGE_DATA_SET/data sets/no'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224,224))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (224,224,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[1]]).toarray())\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "SPDkC9aBCTMa",
        "outputId": "8d4eaac0-1cc0-46ad-cb85-c688ad273130",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1500 1424\n",
            "1500 1467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data, result, test_size=0.2, shuffle = True, random_state = 8)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state= 8)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nxeCda-QCTMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "data.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "q9f_PfzkCTMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.array(result)\n",
        "result = result.reshape(2891,2)"
      ],
      "metadata": {
        "id": "abUknXZxHpLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model1.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model1.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model1.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(units=4096,activation=\"relu\"))\n",
        "model1.add(Dense(units=4096,activation=\"relu\"))\n",
        "model1.add(Dense(units=2, activation=\"softmax\"))\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "opt = Adam(lr=0.001)\n",
        "model1.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "3MY1eQzrCTMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2), strides= (2,2)))\n",
        "\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "from keras.models import Sequential\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(units=4096,activation=\"relu\"))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(4096, activation= 'relu'))\n",
        "model2.add(Dense(1000, activation= 'relu'))\n",
        "model2.add(Dense(2, activation='softmax'))\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "opt = Adam(lr=0.001)\n",
        "model2.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "EO2b8UIPA7Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "2jr6WYMlCTMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model1.fit(x_train, y_train, epochs = 100, batch_size = 40, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "trusted": true,
        "id": "MJuwLt2pCTMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(history)\n",
        "loss_train1 = history1.history['accuracy']\n",
        "loss_val1 = history1.history['val_accuracy']\n",
        "epochs = range(1,101)\n",
        "plt.plot(epochs, loss_train1, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, loss_val1, 'b', label='validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "vjY8T0wgCTMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluate on test data\")\n",
        "results1 = model1.evaluate(x_test, y_test, batch_size=64)\n",
        "print(\"test loss, test acc:\", results1)"
      ],
      "metadata": {
        "id": "JeTamth62jIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history2 = model2.fit(x_train, y_train, epochs = 100, batch_size = 40, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "id": "_w59pvKV50QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train2 = history2.history['accuracy']\n",
        "loss_val2 = history2.history['val_accuracy']\n",
        "epochs = range(1,101)\n",
        "plt.plot(epochs, loss_train2, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, loss_val2, 'b', label='validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k_MfXo3fXavR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluate on test data\")\n",
        "results2 = model2.evaluate(x_test, y_test, batch_size=64)\n",
        "print(\"test loss, test acc:\", results2)"
      ],
      "metadata": {
        "id": "U8eMTK6TvEBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train1 = history1.history['accuracy']\n",
        "loss_val1 = history1.history['val_accuracy']\n",
        "epochs = range(1,101)\n",
        "plt.plot(epochs, loss_train1, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, loss_val1, 'b', label='validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "loss_train2 = history2.history['accuracy']\n",
        "loss_val2 = history2.history['val_accuracy']\n",
        "plt.plot(epochs, loss_train2, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, loss_val2, 'y', label='validation accuracy')\n",
        "plt.title('Training and Validation accuracy Comparision between VGG16 and VGG19 Architecture')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jk-nmyAvvKVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_weights(var_list, weights_file):\n",
        "    with open(weights_file, \"rb\") as fp:\n",
        "        _ = np.fromfile(fp, dtype=np.int32, count=5)        \n",
        "        weights = np.fromfile(fp, dtype=np.float32)"
      ],
      "metadata": {
        "id": "0pdTx5USw26o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YxV8DBvKKOJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important Links:-\n",
        "\n",
        "[SVM](https://towardsdatascience.com/svm-support-vector-machine-for-classification-710a009f6873) \n",
        "\n",
        "[Early Stopping Neural Network](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/)"
      ],
      "metadata": {
        "id": "WhPZ2hBZhPWo"
      }
    }
  ]
}