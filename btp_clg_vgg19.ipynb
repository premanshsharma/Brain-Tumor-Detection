{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "btp-clg vgg19.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOOErirYD2/FhQy+JByKHeG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/premanshsharma/Brain-Tumor-Detection/blob/main/btp_clg_vgg19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lDpBeZmNJ57w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, BatchNormalization, Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "import keras,os\n",
        "import cv2\n",
        "import requests\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc21h_j_J-5U",
        "outputId": "587516b2-2d5d-488c-dcbe-878d2542ebfa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = OneHotEncoder()\n",
        "encoder.fit([[0], [1]]) \n",
        "\n",
        "# 0 - Tumor\n",
        "# 1 - Normal\n",
        "# This cell updates result list for images with tumor\n",
        "\n",
        "data = []\n",
        "paths = []\n",
        "result = []\n",
        "\n",
        "for r, d, f in os.walk(r'/content/gdrive/MyDrive/Brain Tumor Detection/BRAIN_MRI_IMAGE_DATA_SET/data sets/yes'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224,224))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (224,224,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[0]]).toarray())\n",
        "paths = []\n",
        "\n",
        "for r, d, f in os.walk(r'/content/gdrive/MyDrive/Brain Tumor Detection/BRAIN_MRI_IMAGE_DATA_SET/data sets/no'):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            paths.append(os.path.join(r, file))\n",
        "\n",
        "for path in paths:\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224,224))\n",
        "    img = np.array(img)\n",
        "    if(img.shape == (224,224,3)):\n",
        "        data.append(np.array(img))\n",
        "        result.append(encoder.transform([[1]]).toarray())"
      ],
      "metadata": {
        "id": "juDo-ypIKA9e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eEZaS1pKFb-",
        "outputId": "62a638ba-3fbb-4dbe-dcc4-266f53181606"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2891, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.array(result)\n",
        "result = result.reshape(2891,2)"
      ],
      "metadata": {
        "id": "lFtHO4usKHH-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data, result, test_size=0.2, shuffle = True, random_state = 8)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state= 8)\n",
        "# x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
      ],
      "metadata": {
        "id": "Hujdy9_xKI3e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides= (2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "from keras.models import Sequential\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation= 'relu'))\n",
        "model.add(Dense(1000, activation= 'relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "opt = Adam(lr=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
        "# model.summary()\n",
        "# model.compile(optimizer='adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmpK9RStKKT9",
        "outputId": "0344c32b-f188-45f0-923e-0980b26e8fab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape, x_train.shape, x_val.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5d3H1b2Lqrw",
        "outputId": "e64e621b-517f-4d7c-82b0-68726be43ff0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1734, 2), (1734, 224, 224, 3), (578, 224, 224, 3), (578, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs = 50, batch_size = 40, validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERadTENtKyPv",
        "outputId": "bd77e126-2c95-4f4c-df4a-0c5df09978d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "44/44 [==============================] - 4408s 100s/step - loss: 1232.0468 - accuracy: 0.5012 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
            "Epoch 2/50\n",
            "44/44 [==============================] - 4440s 101s/step - loss: 0.7074 - accuracy: 0.5144 - val_loss: 0.6920 - val_accuracy: 0.4913\n",
            "Epoch 3/50\n",
            "44/44 [==============================] - 4412s 100s/step - loss: 0.6926 - accuracy: 0.5029 - val_loss: 0.6899 - val_accuracy: 0.5087\n",
            "Epoch 4/50\n",
            "44/44 [==============================] - 4388s 100s/step - loss: 0.6965 - accuracy: 0.5444 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
            "Epoch 5/50\n",
            "44/44 [==============================] - 4412s 100s/step - loss: 0.6933 - accuracy: 0.5046 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
            "Epoch 6/50\n",
            "13/44 [=======>......................] - ETA: 48:00 - loss: 0.7060 - accuracy: 0.5058"
          ]
        }
      ]
    }
  ]
}